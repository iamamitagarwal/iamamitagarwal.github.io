Authors,Title,Abstract,Link,Publication,Volume,Number,Pages,Year,Publisher
"Agarwal, Amit; Panda, Srikant; Pachauri, Kulbhushan; ",Synthetic document generation pipeline for training artificial intelligence models,"Embodiments described herein are directed towards a synthetic document generation pipeline for training artificial intelligence models. One embodiment includes a method including a device that receives an instruction to generate a document to be used as a training instance for a first machine learning model, the instruction including an element configuration, a document class configuration, a format configuration, an augmentation configuration, and data bias and fairness. The device can receive an element from an interface based at least in part on the element configuration, the element can simulate a real-world image, real-world text, or real-world machine-readable visual code. The device can generate metadata describe a layout for the element on the document based on the document class configuration. The device can generate the document by arranging the element on the document based on the metadata, wherein the document is generated in a format based on the format configuration.",https://patents.google.com/patent/US20240005640A1/en,,,,,2024,"US Patent 20,240,005,640"
"AGARWAL, AMIT; ",Evaluate generalisation & robustness of visual features from images to video,"Unlabeled data has always been more readily available for researchers and industrial applications but supervised learning techniques consistently outperformed unsupervised learning techniques, limiting our capability to capitalise on the massive volume of unlabeled data. Recently, self-supervised learning techniques have attempted to generate supervised signals from unlabeled data to learn a pretask and thus generate general visual representations. However, they are still in their early stage for computer vision tasks due to the different modalities and high-dimensional input signals like images, videos (with audio), 3D objects and geometry. This research studies the generalisation, robustness, and reusability of visual features learned from self-supervised image-based models for video-based tasks like action recognition and action retrieval for UCF101 and HMDB51 datasets. This research proposes a deep learning model that can be trained to adapt visual features learned from image-based models for action recognition and action retrieval task. Finally, clustering and silhouette score analysis is conducted to objectively evaluate the quality of these visual features for video tasks. The trained model head outperforms other video-based models trained on a similar dataset for the action recognition task by a margin greater than 20%. For action retrieval, the performance is highly competitive to the stateof-the-art models trained on much larger datasets than the self-supervised models used in this research. Silhouette score analysis results highlight that the image-based visual features cluster the videos correctly though the cluster boundaries are not very distinctive. The results from the experimental procedures univocally conclude that visual features from self-supervised image-based models can be adapted and reused for video-based tasks. It also highlights that different image-based self-supervised models can adapt to video-based tasks; thus, further studies should explore jointly training selfsupervised models for image and video modalities.",https://www.researchgate.net/profile/Amit-Agarwal-62/publication/363539287_Evaluate_Generalisation_Robustness_of_Visual_Features_from_Images_to_Video/links/6321e7f8071ea12e3632736c/Evaluate-Generalisation-Robustness-of-Visual-Features-from-Images-to-Video.pdf,,,,,2021,December
"Agarwal, Amit; Pachauri, Kulbhushan; Zadeh, Iman; Qian, Jun; ",Techniques for graph data structure augmentation,yet to be published,,,,,,2024,"US Patent 11,989,964"
"Agarwal, Amit; Panda, Srikant; Karmakar, Deepak; Pachauri, Kulbhushan; ",DOMAIN ADAPTING GRAPH NETWORKS FOR VISUALLY RICH DOCUMENTS,Supervised machine learning algorithms can require a considerable volume of labeled data with sufficient variations to learn patterns to generalize and extract key-value pairs from a new set of documents.,https://patents.google.com/patent/US20240289551A1/en,,,,,2024,"US Patent 20,240,289,551"
"Duan, Haodong; Yang, Junming; Qiao, Yuxuan; Fang, Xinyu; Chen, Lin; Liu, Yuan; Dong, Xiaoyi; Zang, Yuhang; Zhang, Pan; Wang, Jiaqi; ",Vlmevalkit: An open-source toolkit for evaluating large multi-modality models,"the available training data may be from general domains and models trained on this data may struggle to classify data from different target domains. Accordingly, improvements in training a model to label key-value labeled documents are desirable.",https://dl.acm.org/doi/abs/10.1145/3664647.3685520,Proceedings of the 32nd ACM international conference on multimedia,,,11198-11201,2024,
"Agarwal, Amit; Patel, Hitesh; Pattnayak, Priyaranjan; Panda, Srikant; Kumar, Bhargava; Kumar, Tejaswini; ",Enhancing Document AI Data Generation Through Graph-Based Synthetic Layouts,"The development of robust Document AI models has been constrained by limited access to high-quality, labeled datasets, primarily due to data privacy concerns, scarcity, and the high cost of manual annotation. Traditional methods of synthetic data generation, such as text and image augmentation, have proven effective for increasing data diversity but often fail to capture the complex layout structures present in real world documents. This paper proposes a novel approach to synthetic document layout generation using Graph Neural Networks (GNNs). By representing document elements (e.g., text blocks, images, tables) as nodes in a graph and their spatial relationships as edges, GNNs are trained to generate realistic and diverse document layouts. This method leverages graph-based learning to ensure structural coherence and semantic consistency, addressing the limitations of traditional augmentation techniques. The proposed framework is evaluated on tasks such as document classification, named entity recognition (NER), and information extraction, demonstrating significant performance improvements. Furthermore, we address the computational challenges of GNN based synthetic data generation and propose solutions to mitigate domain adaptation issues between synthetic and real-world datasets. Our experimental results show that graph-augmented document layouts outperform existing augmentation techniques, offering a scalable and flexible solution for training Document AI models.",https://arxiv.org/abs/2412.03590,International Journal of Engineering Research & Technology,13,10,10,2024,IJERT
"Patel, Hitesh Laxmichand; Agarwal, Amit; Kumar, Bhargava; Gupta, Karan; Pattnayak, Priyaranjan; ",Llm for barcodes: Generating diverse synthetic data for identity documents,"Accurate barcode detection and decoding in Identity documents is crucial for applications like security, healthcare, and education, where reliable data extraction and verification are essential. However, building robust detection models is challenging due to the lack of diverse, realistic datasets an issue often tied to privacy concerns and the wide variety of document formats. Traditional tools like Faker rely on predefined templates, making them less effective for capturing the complexity of real-world identity documents. In this paper, we introduce a new approach to synthetic data generation that uses LLMs to create contextually rich and realistic data without relying on predefined field. Using the vast knowledge LLMs have about different documents and content, our method creates data that reflects the variety found in real identity documents. This data is then encoded into barcode and overlayed on templates for documents such as Driver's licenses, Insurance cards, Student IDs. Our approach simplifies the process of dataset creation, eliminating the need for extensive domain knowledge or predefined fields. Compared to traditional methods like Faker, data generated by LLM demonstrates greater diversity and contextual relevance, leading to improved performance in barcode detection models. This scalable, privacy-first solution is a big step forward in advancing machine learning for automated document processing and identity verification.",https://arxiv.org/abs/2411.14962,arXiv preprint arXiv:2411.14962,,,,2024,
"Didwania, Krish; Seth, Pratinav; Kasliwal, Aditya; Agarwal, Amit; ",AgriLLM: Harnessing Transformers for Farmer Queries,"Agriculture, vital for global sustenance, necessitates innovative solutions due to a lack of organized domain experts, particularly in developing countries where many farmers are impoverished and cannot afford expert consulting. Initiatives like Farmers Helpline play a crucial role in such countries, yet challenges such as high operational costs persist. Automating query resolution can alleviate the burden on traditional call centers, providing farmers with immediate and contextually relevant information. The integration of Agriculture and Artificial Intelligence (AI) offers a transformative opportunity to empower farmers and bridge information gaps. Language models like transformers, the rising stars of AI, possess remarkable language understanding capabilities, making them ideal for addressing information gaps in agriculture. This work explores and demonstrates the transformative potential of Large Language Models (LLMs) in automating query resolution for agricultural farmers, leveraging their expertise in deciphering natural language and understanding context. Using a subset of a vast dataset of real-world farmer queries collected in India, our study focuses on approximately 4 million queries from the state of Tamil Nadu, spanning various sectors, seasonal crops, and query types.",https://arxiv.org/abs/2407.04721,arXiv preprint arXiv:2407.04721,,,,2024,
"Didwania, Krish; Toshniwal, Durga; Agarwal, Amit; ",Unveiling Themes in Judicial Proceedings: A Cross-Country Study Using Topic Modeling on Legal Documents from India and the UK,"Legal documents are indispensable in every country for legal practices and serve as the primary source of information regarding previous cases and employed statutes. In today's world, with an increasing number of judicial cases, it is crucial to systematically categorize past cases into subgroups, which can then be utilized for upcoming cases and practices. Our primary focus in this endeavor was to annotate cases using topic modeling algorithms such as Latent Dirichlet Allocation, Non-Negative Matrix Factorization, and Bertopic for a collection of lengthy legal documents from India and the UK. This step is crucial for distinguishing the generated labels between the two countries, highlighting the differences in the types of cases that arise in each jurisdiction. Furthermore, an analysis of the timeline of cases from India was conducted to discern the evolution of dominant topics over the years.",https://arxiv.org/abs/2406.00040,arXiv preprint arXiv:2406.00040,,,,2024,
"Uniyal, Deepak; Agarwal, Amit; ",IRLCov19: A large COVID-19 multilingual twitter dataset of Indian regional languages,"Emerged in Wuhan city of China in December 2019, COVID-19 continues to spread rapidly across the world despite authorities having made available a number of vaccines. While the coronavirus has been around for a significant period of time, people and authorities still feel the need for awareness due to the mutating nature of the virus and therefore varying symptoms and prevention strategies. People and authorities resort to social media platforms the most to share awareness information and voice out their opinions due to their massive outreach in spreading the word in practically no time. People use a number of languages to communicate over social media platforms based on their familiarity, language outreach, and availability on social media platforms. The entire world has been hit by the coronavirus and India is the second worst-hit country in terms of the number of active coronavirus cases. India, being a multilingual country, offers a great opportunity to study the outreach of various languages that have been actively used across social media platforms. In this study, we aim to study the dataset related to COVID-19 collected in the period between February 2020 to July 2020 specifically for regional languages in India. This could be helpful for the Government of India, various state governments, NGOs, researchers, and policymakers in studying different issues related to the pandemic. We found that English has been the mode of communication in over 64% of tweets while as many as twelve regional languages in India account for approximately 4.77% of tweets .",https://link.springer.com/chapter/10.1007/978-3-030-93733-1_22,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,,,309-324,2021,Springer International Publishing Cham
"Garg, Shivank; Baghel, Abhishek; Agarwal, Amit; Toshniwal, Durga; ","Snowy Scenes, Clear Detections: A Robust Model for Traffic Light Detection in Adverse Weather Conditions","With the rise of autonomous vehicles and advanced driver-assistance systems (ADAS), ensuring reliable object detection in all weather conditions is crucial for safety and efficiency. Adverse weather like snow, rain, and fog presents major challenges for current detection systems, often resulting in failures and potential safety risks. This paper introduces a novel framework and pipeline designed to improve object detection under such conditions, focusing on traffic signal detection where traditional methods often fail due to domain shifts caused by adverse weather. We provide a comprehensive analysis of the limitations of existing techniques. Our proposed pipeline significantly enhances detection accuracy in snow, rain, and fog. Results show a 40.8% improvement in average IoU and F1 scores compared to naive fine-tuning and a 22.4% performance increase in domain shift scenarios, such as training on artificial snow and testing on rain images.",https://arxiv.org/abs/2406.13473,arXiv preprint arXiv:2406.13473,,,,2024,
"Kwon, Hyukseong; Rahimi, Amir; Lee, Kevin G; Agarwal, Amit; Bhattacharyya, Rajan; ",CogSense: A Cognitively Inspired Framework for Perception Adaptation,"This paper proposes the CogSense system, which is inspired by sense-making cognition and perception in the mammalian brain to perform perception error detection and perception parameter adaptation using probabilistic signal temporal logic. As a specific application, a contrast-based perception adaption method is presented and validated. The proposed method evaluates perception errors using heterogeneous probe functions computed from the detected objects and subsequently solves a contrast optimization problem to correct perception errors. The CogSense probe functions utilize the characteristics of geometry, dynamics, and detected blob image quality of the objects to develop axioms in a probabilistic signal temporal logic framework. By evaluating these axioms, we can formally verify whether the detections are valid or erroneous. Further, using the CogSense axioms, we generate the probabilistic signal temporal logic-based constraints to finally solve the contrast-based optimization problem to reduce false positives and false negatives.",https://arxiv.org/abs/2107.10456,arXiv preprint arXiv:2107.10456,,,,2021,
"Bao, Wenlei; Chang, Li-Wen; Chen, Yang; Deng, Ke; Agarwal, Amit; Barsoum, Emad; Taha, Abe; ",Ngemm: Optimizing gemm for deep learning via compiler-based techniques,"Quantization has emerged to be an effective way to significantly boost the performance of deep neural networks (DNNs) by utilizing low-bit computations. Despite having lower numerical precision, quantized DNNs are able to reduce both memory bandwidth and computation cycles with little losses of accuracy. Integer GEMM (General Matrix Multiplication) is critical to running quantized DNN models efficiently, as GEMM operations often dominate the computations in these models. Various approaches have been developed by leveraging techniques such as vectorization and memory layout to improve the performance of integer GEMM. However, these existing approaches are not fast enough in certain scenarios. We developed NGEMM, a compiler-based GEMM implementation for accelerating lower-precision training and inference. NGEMM has better use of the vector units by avoiding unnecessary vector computation that is introduced during tree reduction. We compared NGEMM's performance with the state-of-art BLAS libraries such as MKL. Our experimental results showed that NGEMM outperformed MKL non-pack and pack version by an average of 1.86x and 1.16x, respectively. We have applied NGEMM to a number of production services in Microsoft.",https://arxiv.org/abs/1910.00178,arXiv preprint arXiv:1910.00178,,,,2019,
"Agarwal, Amit; Panda, Srikant; Charles, Angeline; Kumar, Bhargava; Patel, Hitesh; Pattnayak, Priyaranjan; Rafi, Taki Hasan; Kumar, Tejaswini; Chae, Dong-Kyu; ",MVTamperBench: Evaluating Robustness of Vision-Language Models,"Multimodal Large Language Models (MLLMs), are recent advancement of Vision-Language Models (VLMs) that have driven major advances in video understanding. However, their vulnerability to adversarial tampering and manipulations remains underexplored. To address this gap, we introduce MVTamperBench, a benchmark that systematically evaluates MLLM robustness against five prevalent tampering techniques: rotation, masking, substitution, repetition, and dropping; based on real-world visual tampering scenarios such as surveillance interference, social media content edits, and misinformation injection. MVTamperBench comprises~ 3.4 K original videos, expanded into over~ 17K tampered clips covering 19 distinct video manipulation tasks. This benchmark challenges models to detect manipulations in spatial and temporal coherence. We evaluate 45 recent MLLMs from 15+ model families. We reveal substantial variability in resilience across tampering types and show that larger parameter counts do not necessarily guarantee robustness. MVTamperBench sets a new benchmark for developing tamper-resilient MLLM in safety-critical applications, including detecting clickbait, preventing harmful content distribution, and enforcing policies on media platforms. We release all code, data, and benchmark to foster open research in trustworthy video understanding.",https://aclanthology.org/2025.findings-acl.963/,Proceedings of ACL Findings 2025,,,,2024,
"Pattnayak, Priyaranjan; Patel, Hitesh Laxmichand; Kumar, Bhargava; Agarwal, Amit; Banerjee, Ishan; Panda, Srikant; Kumar, Tejaswini; ","Survey of large multimodal model datasets, application categories and taxonomy","Multimodal learning, a rapidly evolving field in artificial intelligence, seeks to construct more versatile and robust systems by integrating and analyzing diverse types of data, including text, images, audio, and video. Inspired by the human ability to assimilate information through many senses, this method enables applications such as text-to-video conversion, visual question answering, and image captioning. Recent developments in datasets that support multimodal language models (MLLMs) are highlighted in this overview. Large-scale multimodal datasets are essential because they allow for thorough testing and training of these models. With an emphasis on their contributions to the discipline, the study examines a variety of datasets, including those for training, domain-specific tasks, and real-world applications. It also emphasizes how crucial benchmark datasets are for assessing models' performance in a range of scenarios, scalability, and applicability. Since multimodal learning is always changing, overcoming these obstacles will help AI research and applications reach new heights.",https://arxiv.org/abs/2412.17759,arXiv preprint arXiv:2412.17759,,,,2024,
"Agarwal, Amit; Panda, Srikant; Pachauri, Kulbhushan; ",FS-DAG: Few shot domain adapting graph networks for visually rich document understanding,"In this work, we propose Few Shot Domain Adapting Graph (FS-DAG), a scalable and efficient model architecture for visually rich document understanding (VRDU) in few-shot settings. FS-DAG leverages domain-specific and language/vision specific backbones within a modular framework to adapt to diverse document types with minimal data. The model is robust to practical challenges such as handling OCR errors, misspellings, and domain shifts, which are critical in real-world deployments. FS-DAG is highly performant with less than 90M parameters, making it well-suited for complex real-world applications for Information Extraction (IE) tasks where computational resources are limited. We demonstrate FS-DAG's capability through extensive experiments for information extraction task, showing significant improvements in convergence speed and performance compared to state-of-the-art methods. Additionally, this work highlights the ongoing progress in developing smaller, more efficient models that do not compromise on performance",https://arxiv.org/abs/2505.17330,arXiv preprint arXiv:2505.17330,,,,2025,
"Cahyawijaya, Samuel; Lovenia, Holy; Moniz, Joel Ruben Antony; Wong, Tack Hwa; Farhansyah, Mohammad Rifqi; Maung, Thant Thiri; Hudi, Frederikus; Anugraha, David; Habibi, Muhammad Ravi Shulthan; Qorib, Muhammad Reza; ","Crowdsource, crawl, or generate? creating sea-vl, a multicultural vision-language dataset for southeast asia","Despite Southeast Asia’s (SEA) extraordinary linguistic and cultural diversity, the region remains significantly underrepresented in vision-language (VL) research, resulting in AI models that inadequately capture SEA cultural nuances. To fill this gap, we present SEA-VL, an open-source initiative dedicated to developing culturally relevant high-quality datasets for SEA languages. By involving contributors from SEA countries, SEA-VL ensures better cultural relevance and diversity, fostering greater inclusivity of underrepresented languages and cultural depictions in VL research. Our methodology employed three approaches: community-driven crowdsourcing with SEA contributors, automated image crawling, and synthetic image generation. We evaluated each method’s effectiveness in capturing cultural relevance. We found that image crawling achieves approximately~ 85% cultural relevance while being more cost-and time-efficient than crowdsourcing, whereas synthetic image generation failed to accurately reflect SEA cultural nuances and contexts. Collectively, we gathered 1.28 million SEA culturally relevant images, more than 50 times larger than other existing datasets. This work bridges the representation gap in SEA, establishes a foundation for developing culturally aware AI systems for this region, and provides a replicable framework for addressing representation gaps in other underrepresented regions.",https://aclanthology.org/2025.acl-long.916/,Proceedings of ACL 2025,,,,2025,
"Panda, Srikant; Agarwal, Amit; Nambirajan, Gouttham; Pachauri, Kulbhushan; ",Out of distribution element detection for information extraction,"Techniques for extracting information from unstructured documents that enable an ML model to be trained such that the model can accurately distinguish in-distribution (“in-D”) elements and out-of-distribution (“OO-D”) elements within an unstructured document. Novel training techniques are used that train an ML model using a combination of a regular training dataset and an enhanced augmented training dataset. The regular training dataset is used to train an ML model to identify in-D elements, i.e., to classify an element extracted from a document as belonging to one of the in-D classes contained in the regular training dataset. The augmented training dataset, which is generated based upon the regular training dataset may contain one or more augmented elements which are used to train the model to identify OO-D elements, i.e., to classify an augmented element extracted from a document as belonging to an OO-D class instead of to an in-D class.",https://patents.google.com/patent/US20250014374A1/en,,,,,2025,US Patent 20250014374A1
"Agarwal, Amit; Kulbhushan, Pachauri; ",Pseudo labelling for key-value extraction from documents,"A computing device may access visually rich documents comprising an image and metadata. A graph, based on the image or metadata, can be generated for a visually rich document. The graph's nodes can correspond to words from the visually rich document. Features for nodes can be determined by the device. The device may generate model labeled graphs by assigning a pseudo-label to nodes using a pretrained model. The device may generate a plurality of graph labeled graphs by assigning a pseudo-label to nodes by matching a first node from a first graph to at least a second node from a second graph. The device may generate a plurality of updated graphs by cross referencing labels from the model labeled graphs and the graph labeled graphs. Until a change in labels is below a threshold, a model can be trained to perform key-value extraction using the updated graphs.",https://patents.google.com/patent/US12106595B2/en,,,,,2024,"US Patent 12,106,595"
"Thomas, Edwin; Agarwal, Amit; Pachauri, Kulbhushan; ",Model augmentation framework for domain assisted continual learning in deep learning,"Techniques are described herein for generating block extender model. An example method includes a system accessing a base model trained for identifying a base class. The system can access an extender comprising block extenders, the extender class distinct from the base class. The system can connect the extender with the base model to generate an augmented model. The system can input training data to the augmented model, the training data is provided to the base model and the extender, the training data comprising data points associated with the extender class. The system can train the extender model to identify the extender class based at least in part on the training data and the signal received from the base machine learning model. The system can generate a trained extender based at least in part on the training, the extender trained to identify an object associated with the extender class.",https://patents.google.com/patent/US20250036962A1/en,,,,,2025,"US Patent App. 18/406,905"
"Pattnayak, Priyaranjan; Laxmichand Patel, Hitesh; Agarwal, Amit; Kumar, Bhargava; Panda, Srikant; Kumar, Tejaswini; ",Improving clinical question answering with multi-task learning: A joint approach for answer extraction and medical categorization,"Clinical Question Answering (CQA) plays a crucial role in medical decision-making, enabling physicians to extract relevant information from Electronic Medical Records (EMRs). While transformer-based models such as BERT, BioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in CQA, existing models lack the ability to categorize extracted answers, which is critical for structured retrieval, content filtering, and medical decision support. To address this limitation, we introduce a Multi-Task Learning (MTL) framework that jointly trains CQA models for both answer extraction and medical categorization. In addition to predicting answer spans, our model classifies responses into five standardized medical categories: Diagnosis, Medication, Symptoms, Procedure, and Lab Reports. This categorization enables more structured and interpretable outputs, making clinical QA models more useful in real-world healthcare settings. We evaluate our approach on emrQA, a large-scale dataset for medical question answering. Results show that MTL improves F1-score by 2.2% compared to standard fine-tuning, while achieving 90.7% accuracy in answer categorization. These findings suggest that MTL not only enhances CQA performance but also introduces an effective mechanism for categorization and structured medical information retrieval.",https://ui.adsabs.harvard.edu/abs/2025arXiv250213108P/abstract,arXiv e-prints,,,arXiv: 2502.13108,2025,
"Agarwal, Amit; Panda, Srikant; Pachauri, Kulbhushan; ",Techniques of information extraction for selection marks,"A computing device may receive a set of user documents. Data may be extracted from the documents to generate a first graph data structure with one or more initial graphs containing key-value pairs. A model may be trained on the first graph data structure to classify the pairs. Until a set of evaluation metrics for the model exceeds a set of deployment thresholds: generating, a set of evaluation metrics may be generated for the model. The set of evaluation metrics may be compared to the set of deployment thresholds. In response to a determination that the set of evaluation metrics are below the set of deployment thresholds: one or more new graphs may be generated from the one or more initial graphs in the first graph data structure to produce a second graph data structure. The first and second graph can be used to train the model.",https://patents.google.com/patent/US11989964B2/en,,,,,2025,"US Patent App. 18/240,343"
"Panda, Srikant; Agarwal, Amit; Pachauri, Kulbhushan; ",Techniques of information extraction for selection marks,"A method may include detecting one or more selection boxes and one or more text lines in a primary document. The method may include determining respective vectors associated with the selection box and adjacent text lines to the selection box in a plurality of directions. The method may include determining a set of respective vectors associated with a unique selection box. The method may include determining a variance between respective vectors in the set of respective vectors and identifying a particular direction corresponding to a minimal variance between the respective vectors in the set of respective vectors as compared to a variance of other sets of respective vectors. The method may include generating a key-value pair based on the set of respective vectors characterized by the minimal variance. The method may include generating a document model, including the key-value pair, and extracting data according to the document model.",https://patents.google.com/patent/US20250078556A1/en,,,,,2025,"US Patent App. 18/240,344"
"Agarwal, Amit; Pachauri, Kulbhushan; ",Pseudo labelling for key-value extraction from documents,"A computing device may access visually rich documents comprising an image and metadata. A graph, based on the image or metadata, can be generated for a visually rich document. The graph's nodes can correspond to words from the visually rich document. Features for nodes can be determined by the device. The device may generate model labeled graphs by assigning a pseudo-label to nodes using a pretrained model. The device may generate a plurality of graph labeled graphs by assigning a pseudo-label to nodes by matching a first node from a first graph to at least a second node from a second graph. The device may generate a plurality of updated graphs by cross referencing labels from the model labeled graphs and the graph labeled graphs. Until a change in labels is below a threshold, a model can be trained to perform key-value extraction using the updated graphs.",https://patents.google.com/patent/US11823478B2/en,,,,,2023,Google Patents
"Pattnayak, Priyaranjan; Agarwal, Amit; Meghwani, Hansa; Patel, Hitesh Laxmichand; Panda, Srikant; ",Hybrid ai for responsive multi-turn online conversations with novel dynamic routing and feedback adaptation,"Retrieval-Augmented Generation (RAG) systems and large language model (LLM)-powered chatbots have significantly advanced conversational AI by combining generative capabilities with external knowledge retrieval. Despite their success, enterprise-scale deployments face critical challenges, including diverse user queries, high latency, hallucinations, and difficulty integrating frequently updated domain-specific knowledge. This paper introduces a novel hybrid framework that integrates RAG with intent-based canned responses, leveraging predefined high-confidence responses for efficiency while dynamically routing complex or ambiguous queries to the RAG pipeline. Our framework employs a dialogue context manager to ensure coherence in multi-turn interactions and incorporates a feedback loop to refine intents, dynamically adjust confidence thresholds, and expand response coverage over time. Experimental results demonstrate that the proposed framework achieves a balance of high accuracy (95%) and low latency (180ms), outperforming RAG and intent-based systems across diverse query types, positioning it as a scalable and adaptive solution for enterprise conversational AI applications.",https://aclanthology.org/2025.knowledgenlp-1.20/,Proceedings of NAACL 2025,,,,2025,
"Pattnayak, Priyaranjan; Patel, Hitesh; Agarwal, Amit; ",Tokenization matters: Improving zero-shot ner for indic languages,"Tokenization is a critical component of Natural Language Processing (NLP), especially for low-resource languages, where subword segmentation influences vocabulary structure and downstream task accuracy. Although Byte-Pair Encoding (BPE) is a standard tokenization method in multilingual language models, its suitability for Named Entity Recognition (NER) in low-resource Indic languages remains underexplored due to its limitations in handling morphological complexity. In this work, we systematically compare BPE, SentencePiece, and Character-Level tokenization strategies using IndicBERT for NER tasks in low-resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as extremely low-resource Indic languages like Santali, Manipuri, and Sindhi. We assess both intrinsic linguistic properties-tokenization efficiency, out-of-vocabulary (OOV) rates, and morphological preservation-as well as extrinsic downstream performance, including fine-tuning and zero-shot cross-lingual transfer. Our experiments show that SentencePiece is a consistently better performing approach than BPE for NER in low-resource Indic Languages, particularly in zero-shot cross-lingual settings, as it better preserves entity consistency. While BPE provides the most compact tokenization form, it is not capable of generalization because it misclassifies or even fails to recognize entity labels when tested on unseen languages. In contrast, SentencePiece constitutes a better linguistic structural preservation model, benefiting extremely low-resource and morpholically rich Indic languages, such as Santali and Manipuri, for superior entity recognition, as well as high generalization across scripts, such as Sindhi, written in Arabic. The results point to SentencePiece as the more effective tokenization strategy for NER within multilingual and low-resource Indic NLP applications.",https://ieeexplore.ieee.org/abstract/document/11103625,2025 IEEE International Conference on Electro Information Technology (eIT),,10.1109/eIT64391.2025.11103625,456-462,2025,IEEE
"Kim, Eunsu; Yoo, Haneul; Son, Guijin; Patel, Hitesh; Agarwal, Amit; Oh, Alice; ",BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation,"As large language models (LLMs) continue to advance, the need for up-to-date and well-organized benchmarks becomes increasingly critical. However, many existing datasets are scattered, difficult to manage, and make it challenging to perform evaluations tailored to specific needs or domains, despite the growing importance of domain-specific models in areas such as math or code. In this paper, we introduce BenchHub, a dynamic benchmark repository that empowers researchers and developers to evaluate LLMs more effectively. BenchHub aggregates and automatically classifies benchmark datasets from diverse domains, integrating 303K questions across 38 benchmarks. It is designed to support continuous updates and scalable data management, enabling flexible and customizable evaluation tailored to various domains or use cases. Through extensive experiments with various LLM families, we demonstrate that model performance varies significantly across domain-specific subsets, emphasizing the importance of domain-aware benchmarking. We believe BenchHub can encourage better dataset reuse, more transparent model comparisons, and easier identification of underrepresented areas in existing benchmarks, offering a critical infrastructure for advancing LLM evaluation research.",https://arxiv.org/abs/2506.00482,arXiv preprint arXiv:2506.00482,,,,2025,
"Meghwani, Hansa; Agarwal, Amit; Pattnayak, Priyaranjan; Patel, Hitesh Laxmichand; Panda, Srikant; ",Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems,"Enterprise search systems often struggle to retrieve accurate, domain-specific information due to semantic mismatches and overlapping terminologies. These issues can degrade the performance of downstream applications such as knowledge management, customer support, and retrieval-augmented generation agents. To address this challenge, we propose a scalable hard-negative mining framework tailored specifically for domain-specific enterprise data. Our approach dynamically selects semantically challenging but contextually irrelevant documents to enhance deployed re-ranking models. Our method integrates diverse embedding models, performs dimensionality reduction, and uniquely selects hard negatives, ensuring computational efficiency and semantic precision. Evaluation on our proprietary enterprise corpus (cloud services domain) demonstrates substantial improvements of 15\% in MRR@3 and 19\% in MRR@10 compared to state-of-the-art baselines and other negative sampling techniques. Further validation on public domain-specific datasets (FiQA, Climate Fever, TechQA) confirms our method's generalizability and readiness for real-world applications.",https://arxiv.org/abs/2505.18366,Proceedings of ACL Industry Track 2025,,,,2025,
"Pattnayak, Priyaranjan; Agarwal, Amit; Kumar, Bhargava; Bangera, Yeshil; Panda, Srikant; Kumar, Tejaswini; Patel, Hitesh Laxmichand; ",Review of reference generation methods in large language models,"Large Language Models (LLMs) are now central to a wide range of applications, from academic writing and legal analysis to scientific research. Yet, one area that has consistently challenged their broader adoption is the problem of accurate and verifiable citation generation. Hallucinated or inaccurate citations erode trust, so it is essential to create reliable methods of citation generation. This survey covers notable approaches used to improve citation generation in LLMs, including Retrieval-Augmented Generation (RAG), prompt engineering, instruction tuning, and incorporating external knowledge. We also cover emerging approaches such as multimodal citation generation using structured data and visual information for improved accuracy. A survey of evaluation metrics, benchmark datasets, and ethical concerns—such as biases, risks of misinformation, and transparency—identifies current limitations and possible areas of improvement.",https://openreview.net/pdf?id=eB87ISzlL1,IJAIML,9339,,1263,2024,
"Pattnayak, Priyaranjan; Patel, Hitesh Laxmichand; Agarwal, Amit; Kumar, Bhargava; Panda, Srikant; Kumar, Tejaswini; ",Clinical qa 2.0: Multi-task learning for answer extraction and categorization,"Clinical Question Answering (CQA) plays a crucial role in medical decision-making, enabling physicians to extract relevant information from Electronic Medical Records (EMRs). While transformer-based models such as BERT, BioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in CQA, existing models lack the ability to categorize extracted answers, which is critical for structured retrieval, content filtering, and medical decision support. To address this limitation, we introduce a Multi-Task Learning (MTL) framework that jointly trains CQA models for both answer extraction and medical categorization. In addition to predicting answer spans, our model classifies responses into five standardized medical categories: Diagnosis, Medication, Symptoms, Procedure, and Lab Reports. This categorization enables more structured and interpretable outputs, making clinical QA models more useful in real-world healthcare settings. We evaluate our approach on emrQA, a large-scale dataset for medical question answering. Results show that MTL improves F1-score by 2.2% compared to standard fine-tuning, while achieving 90.7% accuracy in answer categorization. These findings suggest that MTL not only enhances CQA performance but also introduces an effective mechanism for categorization and structured medical information retrieval.",https://arxiv.org/abs/2502.13108,2025 IEEE International Conference on Electro Information Technology (eIT),,10.1109/eIT64391.2025.11103631,7-Jan,2025,
"Patel, Hitesh Laxmichand; Agarwal, Amit; Panda, Srikant; Meghwani, Hansa; Dua, Karan; Li, Paul; Sheng, Tao; Ravi, Sujith; Roth, Dan; ",Pcri: Measuring context robustness in multimodal models for enterprise applications,"The reliability of Multimodal Large Language Models (MLLMs) in real-world settings is often undermined by sensitivity to irrelevant or distracting visual context, an aspect not captured by existing evaluation metrics. We introduce the \textbf{Patch Context Robustness Index (PCRI)}, the first systematic and interpretable score for quantifying MLLM robustness to variations in visual context granularity, measuring performance changes between localized image patches and full-image input. Applying PCRI to 19 state-of-the-art MLLMs across 15 vision-language benchmarks, we find that most leading models remain brittle to background noise, with only a few, such as InternVL2-26B and Qwen2VL-72B, demonstrating consistent robustness across tasks. PCRI analysis also highlights how different model architectures handle and integrate visual context, offering actionable diagnostic insight for both researchers and practitioners. PCRI enables rigorous comparison of context robustness, supporting principled model selection and guiding the development of future architectures and training strategies for robust, real-world deployment.",https://ui.adsabs.harvard.edu/abs/2025arXiv250923879L/abstract,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track,,,195-214,2025,
"Agarwal, Amit; Patel, Hitesh Laxmichand; Panda, Srikant; Meghwani, Hansa; Singh, Jyotika; Dua, Karan; Li, Paul; Sheng, Tao; Ravi, Sujith; Roth, Dan; ",RCI: A Score for Evaluating Global and Local Reasoning in Multimodal Benchmarks,"Multimodal Large Language Models (MLLMs) have achieved impressive results on vision-language benchmarks, yet it remains unclear whether these benchmarks assess genuine global reasoning or allow success via localized visual cues. Existing evaluation methods do not explicitly measure this distinction, hindering effective dataset curation and real-world focused model development. We introduce Region Comprehension Index (RCI), the first model-based score to directly quantify a dataset’s reliance on global versus local visual information. RCI systematically compares reference-model performance on image patches versus full images, revealing if tasks require holistic image understanding or can be solved with partial or localized visual cues. When applying RCI to 13 widely used multimodal benchmarks, we observed that most of them favor localized reasoning and exhibit significant spatial biases, indicating potential risks in real-world applications. RCI equips researchers & practitioners with an actionable tool for diagnosing & mitigating these biases, enabling the construction of datasets and benchmarks to foster the development of robust, enterprise-ready multimodal systems.",https://aclanthology.org/2025.emnlp-industry.10/,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track,,,138-157,2025,
"Hari, Vishnu; Panda, Kalpana; Panda, Srikant; Agarwal, Amit; Patel, Hitesh Laxmichand; ",Who's Asking? Investigating Bias Through the Lens of Disability-Framed Queries in LLMs,"Large Language Models (LLMs) routinely infer users' demographic traits from phrasing alone, which can result in biased responses, even when no explicit demographic information is provided. The role of disability cues in shaping these inferences remains largely uncharted. Thus, we present the first systematic audit of disability-conditioned demographic bias across eight state-of-the-art instruction-tuned LLMs ranging from 3B to 72B parameters. Using a balanced template corpus that pairs nine disability categories with six real-world business domains, we prompt each model to predict five demographic attributes - gender, socioeconomic status, education, cultural background, and locality - under both neutral and disability-aware conditions. Across a varied set of prompts, models deliver a definitive demographic guess in up to 97% of cases, exposing a strong tendency to make arbitrary inferences with no clear justification. Disability context heavily shifts predicted attribute distributions, and domain context can further amplify these deviations. We observe that larger models are simultaneously more sensitive to disability cues and more prone to biased reasoning, indicating that scale alone does not mitigate stereotype amplification. Our findings reveal persistent intersections between ableism and other demographic stereotypes, pinpointing critical blind spots in current alignment strategies. We release our evaluation framework and results to encourage disability-inclusive benchmarking and recommend integrating abstention calibration and counterfactual fine-tuning to curb unwarranted demographic inference. Code and data will be released on acceptance.",https://openaccess.thecvf.com/content/ICCV2025W/CV4A11y/html/Hari_Whos_Asking_Investigating_Bias_Through_the_Lens_of_Disability-Framed_Queries_ICCVW_2025_paper.html,Proceedings of the IEEE/CVF International Conference on Computer Vision,,,6644-6655,2025,
"Panda, Srikant; Patel, Hitesh Laxmichand; Al-Khalifa, Shahad; Agarwal, Amit; Al-Khalifa, Hend; Al-Ghamdi, Sharefah; ",DAIQ: Auditing Demographic Attribute Inference from Question in LLMs,"Large Language Models (LLMs) are known to reflect social biases when demographic attributes, such as gender or race, are explicitly present in the input. But even in their absence, these models still infer user identities based solely on question phrasing. This subtle behavior has received far less attention, yet poses serious risks: it violates expectations of neutrality, infers unintended demographic information, and encodes stereotypes that undermine fairness in various domains including healthcare, finance and education. We introduce Demographic Attribute Inference from Questions (DAIQ), a task and framework for auditing an overlooked failure mode in language models: inferring user demographic attributes from questions that lack explicit demographic cues. Our approach leverages curated neutral queries, systematic prompting, and both quantitative and qualitative analysis to uncover how models infer demographic information. We show that both open and closed source LLMs do assign demographic labels based solely on question phrasing. Prevalence and consistency of demographic inferences across diverse models reveal a systemic and underacknowledged risk: LLMs can fabricate demographic identities, reinforce societal stereotypes, and propagate harms that erode privacy, fairness, and trust posing a broader threat to social equity and responsible AI deployment. To mitigate this, we develop a prompt-based guardrail that substantially reduces identity inference and helps align model behavior with fairness and privacy objectives.",https://arxiv.org/abs/2508.15830,arXiv preprint arXiv:2508.15830,,,,2025,
"Agarwal, Amit; Meghwani, Hansa; Patel, Hitesh Laxmichand; Sheng, Tao; Ravi, Sujith; Roth, Dan; ",Aligning llms for multilingual consistency in enterprise applications,"Large language models (LLMs) remain unreliable for global enterprise applications due to substantial performance gaps between high-resource and mid/low-resource languages, driven by English-centric pretraining and internal reasoning biases. This inconsistency undermines customer experience and operational reliability in multilingual settings such as customer support, content moderation, and information retrieval. Even with advanced Retrieval-Augmented Generation (RAG) systems, we observe up to an 29% accuracy drop in non-English languages compared to English. We propose a practical, batch-wise alignment strategy for fine-tuning LLMs, leveraging semantically equivalent multilingual data in each training batch to directly align model outputs across languages. This approach improves non-English accuracy by up to 23.9% without compromising English performance, model reasoning, or retrieval quality. Our method is simple to implement, scalable, and integrates seamlessly with existing LLM training & deployment pipelines, enabling more robust and equitable multilingual AI solutions in industry.",https://aclanthology.org/2025.emnlp-industry.9/,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track,,,117-137,2025,
"Patel, Hitesh Laxmichand; Agarwal, Amit; ",SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use,"Enterprise customers are increasingly adopting Large Language Models (LLMs) for critical communication tasks, such as drafting emails, crafting sales pitches, and composing casual messages. Deploying such models across different regions requires them to understand diverse cultural and linguistic contexts and generate safe and respectful responses. For enterprise applications, it is crucial to mitigate reputational risks, maintain trust, and ensure compliance by effectively identifying and handling unsafe or offensive language. To address this, we introduce SweEval, a benchmark simulating real-world scenarios with variations in tone (positive or negative) and context (formal or informal). The prompts explicitly instruct the model to include specific swear words while completing the task. This benchmark evaluates whether LLMs comply with or resist such inappropriate instructions and assesses their alignment with ethical frameworks, cultural nuances, and language comprehension capabilities.",https://arxiv.org/abs/2505.17332,Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies,3,,558-582,2024,
"Dua, Karan; Patel, Hitesh Laxmichand; Mittal, Puneet; Gupta, Ranjeet; Agarwal, Amit; Pabolu, Praneet; Panda, Srikant; Meghwani, Hansa; Horwood, Graham; Shah, Fahad; ",FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic Documents for Training Document Understanding Models,"Developing document understanding models at enterprise scale requires large, diverse, and well-annotated datasets spanning a wide range of document types. However, collecting such data is prohibitively expensive due to privacy constraints, legal restrictions, and the sheer volume of manual annotation needed-costs that can scale into millions of dollars. We introduce FlexDoc, a scalable synthetic data generation framework that combines Stochastic Schemas and Parameterized Sampling to produce realistic, multilingual semi-structured documents with rich annotations. By probabilistically modeling layout patterns, visual structure, and content variability, FlexDoc enables the controlled generation of diverse document variants at scale. Experiments on Key Information Extraction (KIE) tasks demonstrate that FlexDoc-generated data improves the absolute F1 Score by up to 11% when used to augment real datasets, while reducing annotation effort by over 90% compared to traditional hard-template methods. The solution is in active deployment, where it has accelerated the development of enterprise-grade document understanding models while significantly reducing data acquisition and annotation costs.",https://aclanthology.org/2025.emnlp-industry.105/,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track,,,1500-1521,2025,
"Yadav, Sourabh; Agarwal, Amit; Pachauri, Kulbhushan; ",Fine-grained activity recognition using machine learning,"The present disclosure relates to a custom framework for fine-grained human activity recognition. One or more input videos may be accessed, where the one or more input videos comprise one or more frames depicting one or more actors and one or more objects. A plurality of object-pose interaction graphs may be generated for individual frames from the one or more input videos based at least in part on one or more objects of interest from the one or more objects and on one or more joint keypoints of the one or more actors. A first graph neural network may be trained based at least in part on the plurality of object-pose interaction graphs to identify spatial information for the one or more actors, the one or more objects of interest, and one or more interactions between the one or more actors and the one or more objects of interest. A second graph neural network may be trained based at least in part on the plurality of object-pose interaction graphs and one or more keyframes from the plurality of frames to identify temporal information for the one or more actors, the one or more objects of interest, and the one or more interactions between the one or more actors and the one or more objects of interest. A classifier may be trained to identify one or more actions in the one or more input videos based at least in part on the spatial information and the temporal information.",https://patents.google.com/patent/US20250232584A1/en,,,,,2025,Google Patents
"Panda, Srikant; Agarwal, Amit; Patel, Hitesh Laxmichand; ",Accesseval: Benchmarking disability bias in large language models,"Large Language Models (LLMs) are increasingly deployed across diverse domains but often exhibit disparities in how they handle real life queries. To systematically investigate these effects with various disability context, we introduce AccessEval, a large-scale benchmark evaluating total 21 close & open source LLMs across six real-world domains and nine disability types using paired Neutral and Disability-Aware Queries. We evaluated model outputs with metrics for factual accuracy, sentiment, and social perception. Our analysis reveals that responses to disability-aware queries tend to have higher factual error, more negative tone, and increased stereotyping with social perception compared to neutral queries. These effects show notable variation by domain and disability type. Disabilities affecting hearing, speech and mobility are disproportionately impacted. These disparities reveal persistent forms of ableism, highlighting the need for more comprehensive and nuanced assessment. We further argue that framing bias in terms of model performance within real-world decision making helps to better link model behaviors to the potential harms users may face. This approach guides the development of more effective and tailored fairness interventions. AccessEval, therefore, serves as a crucial tool for advancing equitable and inclusive language technologies.",https://aclanthology.org/2025.emnlp-main.1653/,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing,,,32492-32518,2025,
"Panda, Srikant; Agarwal, Amit; Pachauri, Kulbhushan; ",Dynamic vocabularies for conditioning a language model for transforming natural language to a logical form,"Techniques are disclosed herein for generating dynamic vocabularies for conditioning a language model. A dynamic vocabulary is constructed from an input prompt, database schema information for a database to be queried, and programming language information for a programming language to be used for querying the database to condition the language model to predict an output statement in the programming language. The dynamic vocabulary can be included in prompt information that is provided to the language model. The number of tokens in the dynamic vocabulary can be different than a number of tokens included in a vocabulary of the language model. By utilizing a dynamic vocabulary, the language model can be conditioned to predict tokens for the output statement that are contextually consistent with the tokens included the dynamic vocabulary.",https://patents.google.com/patent/US20250238614A1/en,,,,,2025,Google Patents
"Son, Guijin; Yang, Donghun; Patel, Hitesh Laxmichand; Agarwal, Amit; Ko, Hyunwoo; Lim, Chanuk; Panda, Srikant; Kim, Minhyuk; Drolia, Nikunj; Choi, Dasol; ",Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought,"Recent frontier models employ long chain-of-thought reasoning to explore solution spaces in context and achieve stonger performance. While many works study distillation to build smaller yet capable models, most focus on English and little is known about language-specific reasoning. To bridge this gap, we first introduct **Language-Mixed CoT**, a reasoning schema that switches between English and a target language, using English as an anchor to excel in reasoning while minimizing translation artificats. As a Korean case study, we curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5, Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves state-of-the-art performance, with the highest overall average score (64.0 \pm 25), ranking first on 5/9 benchmarks and second on the remainder. Samller and mid-sized models also benefit substantially, with an average improvement of +18.6 points across teh evaluated nine benchmarks. Ablations show **Language-Mixed CoT** is more effective than monolingual CoT, also resulting in cross-lingual and mult-modal performance gains. We release our data-curation pipeline, evaluation system, datasets, and models to advance research on language-specific reasoning. Data and model collection: https://huggingface.co/KOREAson.",https://arxiv.org/abs/2510.04230,arXiv preprint arXiv:2510.04230,,,,2025,
"Laxmichand Patel, Hitesh; Agarwal, Amit; Panda, Srikant; Meghwani, Hansa; Dua, Karan; Li, Paul; Sheng, Tao; Ravi, Sujith; Roth, Dan; ",PCRI: Measuring Context Robustness in Multimodal Models for Enterprise Applications,"The reliability of Multimodal Large Language Models (MLLMs) in real-world settings is often undermined by sensitivity to irrelevant or distracting visual context, an aspect not captured by existing evaluation metrics. We introduce the Patch Context Robustness Index (PCRI), the first systematic and interpretable score for quantifying MLLM robustness to variations in visual context granularity, measuring performance changes between localized image patches and full-image input. Applying PCRI to 19 state-of-the-art MLLMs across 15 vision-language benchmarks, we find that most leading models remain brittle to background noise, with only a few, such as InternVL2-26B and Qwen2VL-72B, demonstrating consistent robustness across tasks. PCRI analysis also highlights how different model architectures handle and integrate visual context, offering actionable diagnostic insight for both researchers and practitioners. PCRI enables rigorous comparison of context robustness, supporting principled model selection and guiding the development of future architectures and training strategies for robust, real-world deployment.",https://aclanthology.org/2025.emnlp-industry.14/,arXiv e-prints,,,arXiv: 2509.23879,2025,
"Wasi, Azmine Toushik; Islam, Mst Rafia; Rahman, Abdur; Yeasmin, Tawfia; Agarwal, Amit; Patel, Hitesh Laxmichand; Rafi, Taki Hasan; Chae, Dong-Kyu; ",LegalMind: An Intelligent Solution for Legal Document Analysis with User-Centric UI and AI-Driven Capabilities in Mobile Devices,"Navigating legal documents is challenging due to their complexity, jargon, and interconnected entities like names, dates, and provisions, leading to inefficiencies and critical oversights. With the growing reliance on mobile devices, there is an increasing demand for tools that enable efficient and accessible legal document analysis on-the-go. To address these issues, we introduce LegalMind, a mobile app that revolutionizes legal document analysis by integrating key features: Automatic Entity Mapping for quick identification of essential details, Intelligent Question Answering for context-aware responses, and Multi-document Analysis for comprehensive comparison. Designed with a user-centric UI, LegalMind streamlines information retrieval, reduces manual effort, and enhances decision-making for legal professionals. The intuitive UI allows users to easily navigate complex legal content on mobile devices. Our user study confirmed that LegalMind improves efficiency and accessibility, thus showing its ability to transform legal workflows by bridging the gap between complex legal challenges and AI-driven solutions while maintaining a seamless, accessible UI.",https://dl.acm.org/doi/abs/10.1145/3715070.3749262,Companion Publication of the 2025 Conference on Computer-Supported Cooperative Work and Social Computing,,,410-414,2025,
"Meena, Kapil Kumar; Bairwa, Deepak; Agarwal, Amit; ",A machine learning approach for unraveling the influence of air quality awareness on travel behavior,"Urbanization has escalated air pollution levels with subsequent health implications. This study explores the potential of awareness about air quality levels on travelers’ choices and proposes machine learning models to predict travel mode under exposure to different air quality levels. These models are Random Forest, XGBoost, Naive Bayes (NB), K-Nearest Neighbor, Support Vector Machine (SVM), and Multinomial Logistic Regression (MLR). The models are trained using data from individuals who have an understanding of air quality levels. The trained model is further used to predict travel mode choices when the knowledge of air quality reaches all travelers. Travel modes are aggregated into open/closed modes, private/public modes, and motorized/non-motorized/metro modes to assess the impact of air quality awareness and modal shift.",https://www.sciencedirect.com/science/article/pii/S2772662224000638,Decision Analytics Journal,11,,100459,2024,Elsevier
"Potdar, Saloni; Barahona, Lina M Rojas; Montella, Sebastien; ",Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track,"Welcome to EMNLP Industry Track 2025! The EMNLP 2025 Industry Track highlights the key insights, novel research trends and challenges encountered in the design, development and deployment of practical language technology applications. Relevant topics include efficiency, maintainability, and scalability of the real-world, novel use cases, methods, and applications.
The main goal of the Industry Track is to be the foremost venue for bridging the gap and sharing insights between academia and industry. The track made its debut in ACL conferences at the NAACL 2018 and was first introduced to EMNLP in 2022. This year is the fourth edition of the Industry Track at EMNLP. We are thrilled to have received a record 449 submissions to the Industry Track this year, a hundred more submissions than last year. A total of 38 area chairs, out of which 16 with industry affiliations, were recruited to handle the submissions. Each paper underwent review by at least three program committee members, with area chairs providing a meta-review and recommendation. We encouraged an authorreviewer discussion stage for the Industry Track.",https://aclanthology.org/2025.emnlp-industry.0.pdf,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track,,,,2025,
